{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from numpy import linalg as la\n",
    "import math\n",
    "from scipy.ndimage import filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal length\n",
    "FOCAL_LENGTH = 668\n",
    "# cylinder radius, it's much better to use focal length\n",
    "CYLINDER_RADIUS = FOCAL_LENGTH\n",
    "RANSAC_THRESHHOLD = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show img for testing\n",
    "def show_image_by_OpenCV(img):\n",
    "    cv2.imshow('My Image', img )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, devide=1):\n",
    "    paths = sorted(glob.glob(os.path.join(folder,'*')))\n",
    "    images = [cv2.imread(i) for i in paths]\n",
    "    images = [cv2.resize(i, (i.shape[1]//devide, i.shape[0]//devide), interpolation=cv2.INTER_AREA) for i in images]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonmax_suppression(image):\n",
    "    \n",
    "    NONMAX_SUPPRESSION_KERNEL = 7\n",
    "    STRIDE=7\n",
    "\n",
    "    result = np.zeros((image.shape))\n",
    "    \n",
    "    _image = np.lib.stride_tricks.sliding_window_view(image, NONMAX_SUPPRESSION_KERNEL, 1)[:,::STRIDE]\n",
    "    _image = np.lib.stride_tricks.sliding_window_view(_image, NONMAX_SUPPRESSION_KERNEL, 0)[::STRIDE,:]\n",
    "    # print(_image.shape)\n",
    "    _image = np.reshape(_image,(*_image.shape[:2],-1))\n",
    "    _image = np.argmax(_image, axis=2)\n",
    "\n",
    "    mg = np.mgrid[0:_image.shape[0],0:_image.shape[1]]\n",
    "\n",
    "    # y offset: mg[0], x offset: mg[1]\n",
    "    index_y = _image // NONMAX_SUPPRESSION_KERNEL + mg[0] * STRIDE \n",
    "    index_x = _image % NONMAX_SUPPRESSION_KERNEL + mg[1] * STRIDE \n",
    "    index_x, index_y = index_x.flatten(), index_y.flatten()\n",
    "\n",
    "\n",
    "    for i, j in zip(index_y, index_x):\n",
    "        result[i][j]=image[i][j]  \n",
    "        \n",
    "    return  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_Harris_corner(image, THRESHOLD=300):\n",
    "    # # parameters\n",
    "    K = 0.04\n",
    "\n",
    "    # #  Compute x and y derivatives of image.\n",
    "    # # rgb to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "    # R = compute_harris_responce(image)\n",
    "    \n",
    "    # gaussion \n",
    "    # gradient\n",
    "    \n",
    "    I_y = np.zeros(image.shape)\n",
    "    I_x = np.zeros(image.shape)\n",
    "\n",
    "    filters.gaussian_filter(image, (1.5, 1.5), (1,0), I_y)\n",
    "    filters.gaussian_filter(image, (1.5, 1.5), (0,1), I_x)\n",
    "\n",
    "\n",
    "    # Compute products of derivates at each pixel.\n",
    "    I_xx = I_x * I_x\n",
    "    I_yy = I_y * I_y\n",
    "    I_xy = I_x * I_y\n",
    "\n",
    "    # # Compute the sums of the products of derivates at each pixel.\n",
    "    # # weight : use gaussian\n",
    "    # # Define the matrix M.\n",
    "    # # | S_xx  S_xy |\n",
    "    # # | S_xy  S_yy |\n",
    "    \n",
    "    S_xx = filters.gaussian_filter(I_xx, 1.5)\n",
    "    S_xy = filters.gaussian_filter(I_xy, 1.5)\n",
    "    S_yy = filters.gaussian_filter(I_yy, 1.5)\n",
    "\n",
    "    # # Compute the response of the detector at each pixel\n",
    "    detM = S_xx * S_yy - S_xy * S_xy\n",
    "    traceM = S_xx + S_yy\n",
    "    # R = detM - K * (traceM * traceM)\n",
    "    \n",
    "    R = detM / (traceM +1e-8)\n",
    "\n",
    "    # # Nonmax Suppression\n",
    "    R = nonmax_suppression(R)\n",
    "    \n",
    "    # # Threshold on value of R\n",
    "    R[R < THRESHOLD] = 0\n",
    "    R[R > 0] = 255\n",
    "\n",
    "    # 濾邊界\n",
    "    R[:20 , :] = 0\n",
    "    R[: ,:20 ] = 0\n",
    "    R[-20:, :] = 0\n",
    "    R[:,-20: ] = 0\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_descriptor(feature_mask, image):\n",
    "\n",
    "    Gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gau_img = cv2.GaussianBlur(Gray_img, (3,3), 4.5)\n",
    "    sobel_y = cv2.Sobel(gau_img, cv2.CV_64F, 0, 1)\n",
    "    sobel_x = cv2.Sobel(gau_img, cv2.CV_64F, 1, 0)\n",
    "    _, angle = cv2.cartToPolar(sobel_x, sobel_y, angleInDegrees=True)\n",
    "    # print(angle.dtype)\n",
    "    DESCRIPTOR_SIZE = 40\n",
    "    KERNEL = 5\n",
    "\n",
    "    # descriptor size: 40*40\n",
    "    feature_point_y, feature_point_x = np.nonzero(feature_mask)\n",
    "    index_to_get = [KERNEL//2 + i * KERNEL for i in range(DESCRIPTOR_SIZE//KERNEL)]\n",
    "    # 5*5 sum/mean -> 8*8(descriptor matrix)\n",
    "\n",
    "    descriptors = []\n",
    "    positions = []\n",
    "    for y, x in zip(feature_point_y, feature_point_x):\n",
    "        y, x = int(y), int(x)\n",
    "        rot_M = cv2.getRotationMatrix2D((x,y),angle[y,x],1) # (旋轉中心),旋轉角度,縮放比例\n",
    "        img_rotate = cv2.warpAffine(gau_img,rot_M,(gau_img.shape[1],gau_img.shape[0]), flags = cv2.INTER_NEAREST)\n",
    "\n",
    "        # 取feature_point-20~+19之間的值，做boxfilter\n",
    "        big_matrix = img_rotate[y-DESCRIPTOR_SIZE//2:y+DESCRIPTOR_SIZE//2, x-DESCRIPTOR_SIZE//2:x+DESCRIPTOR_SIZE//2]\n",
    "        big_matrix = cv2.boxFilter(big_matrix, -1, (KERNEL, KERNEL))\n",
    "        # print(big_matrix.dtype)\n",
    "        # size = (8, 8)\n",
    "        descriptor = np.zeros((DESCRIPTOR_SIZE//KERNEL, DESCRIPTOR_SIZE//KERNEL))\n",
    "        for i in range(DESCRIPTOR_SIZE//KERNEL):\n",
    "            for j in range(DESCRIPTOR_SIZE//KERNEL):\n",
    "                descriptor[i][j] = big_matrix[index_to_get[i]][index_to_get[j]]\n",
    "        descriptor = (descriptor - np.mean(descriptor)) / np.std(descriptor)\n",
    "        descriptors.append(descriptor)\n",
    "        positions.append([y, x])\n",
    "\n",
    "    return np.array(descriptors), np.array(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match_poing(descriptors_1, positions_1, descriptors_2, positions_2, LOW_THERESHOLD=3):\n",
    "    match_point = []\n",
    "    # match_dis = []\n",
    "    \n",
    "    for ds1, ps1 in zip(descriptors_1, positions_1):\n",
    "        min_dis = 99999\n",
    "        min_pos = [-1, -1]\n",
    "\n",
    "        for ds2, ps2 in zip(descriptors_2, positions_2):\n",
    "            dis = np.linalg.norm(ds1 - ds2)\n",
    "\n",
    "            if(dis<min_dis):\n",
    "                min_dis = dis\n",
    "                min_pos = np.array([*ps1, *ps2])\n",
    "                \n",
    "        if(min_dis<LOW_THERESHOLD):\n",
    "            match_point.append(min_pos)\n",
    "            # match_dis.append(min_dis)\n",
    "    return match_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(descriptors_1, positions_1, descriptors_2, positions_2):\n",
    "    # print('find_match_poing1')\n",
    "    match_point_to_1 = find_match_poing(descriptors_1, positions_1, descriptors_2, positions_2)\n",
    "    \n",
    "    # print('find_match_poing2')\n",
    "    match_point_to_2 = find_match_poing(descriptors_2, positions_2, descriptors_1, positions_1)\n",
    "\n",
    "    # print('merge')\n",
    "    match_point = []\n",
    "    for match_1 in match_point_to_1:\n",
    "        for match_2 in match_point_to_2:\n",
    "            dis_1 = np.linalg.norm(match_1[:2]-match_2[-2:])\n",
    "            dis_2 = np.linalg.norm(match_1[-2:]-match_2[:2])\n",
    "            \n",
    "            if(dis_1+dis_2==0):\n",
    "                match_point.append(match_1)\n",
    "                \n",
    "    return np.array(match_point)\n",
    "    \n",
    "    # [pos1_y, pos1_x, pos2_y, pos2_x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point(img, R, output, outputName, r, g, b):\n",
    "    for i in range(R.shape[0]):\n",
    "        for j in range(R.shape[1]):\n",
    "            if (R[i][j]>1):\n",
    "                img = cv2.circle(img, (j, i), 2, (b, g, r), 2)\n",
    "    if(output):\n",
    "        cv2.imwrite(f\"{outputName}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_matching_image(images):\n",
    "    print('Detecting Harris corner.')\n",
    "    imgs_detect_Harris_corner = [detect_Harris_corner(i) for i in images]\n",
    "    \n",
    "    print('Genetating images feature descriptor.')\n",
    "    # for i, j in zip(images, imgs_detect_Harris_corner):\n",
    "    #     draw_point(i, j, 0, '', 255, 0, 0) \n",
    "    dsps = [feature_descriptor(i, j)for i,j in zip(imgs_detect_Harris_corner, images)]\n",
    "    match_points = []\n",
    "\n",
    "    print('Matching descriptor.')\n",
    "    for i in range(1, len(images)):\n",
    "        match_points.append(matching(dsps[i-1][0], dsps[i-1][1], dsps[i][0], dsps[i][1]))\n",
    "    return match_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_match_line(imgs, match_points):\n",
    "    for i in range(len(match_points)): \n",
    "        img_concat = np.concatenate((imgs[i], imgs[i+1]), axis=1)\n",
    "        img_w = imgs[i].shape[1]\n",
    "        for j in match_points[i]:\n",
    "            img_concat = cv2.line(img_concat, (j[1], j[0]), (j[3]+img_w, j[2]), (255,0,0), 1)\n",
    "\n",
    "        cv2.imwrite(f'result{i}_{i+1}.jpg', img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's better to use random sample\n",
    "def nonRANSAC(mp, th = RANSAC_THRESHHOLD): # mp = match pairs set of all images\n",
    "    best_mp = []\n",
    "    \n",
    "    for i in range(len(mp)): # every pairs of different img img_x & img_x+1\n",
    "        best_vote = 0\n",
    "        best_mp.append(mp[i][0])\n",
    "        for j in range(len(mp[i])): # find the best pair of the two images\n",
    "            vote = 0\n",
    "            temp_pair = np.array(mp[i][:, 0:2])\n",
    "            trans_y = mp[i][j][2] - mp[i][j][0]\n",
    "            trans_x = mp[i][j][3] - mp[i][j][1]\n",
    "            temp_pair[0] += trans_y \n",
    "            temp_pair[1] += trans_x\n",
    "            for k in range(len(temp_pair)):\n",
    "                if(k == j):\n",
    "                    continue\n",
    "                if(la.norm(temp_pair[k]) < th):\n",
    "                    vote += 1\n",
    "\n",
    "            if(vote > best_vote):\n",
    "                best_vote = vote\n",
    "                best_mp[i] = mp[i][j]\n",
    "\n",
    "    return best_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_cylinder(img, f = FOCAL_LENGTH, s = CYLINDER_RADIUS):\n",
    "    height, width = img.shape[:2]\n",
    "    cylinder_proj = np.zeros(shape=img.shape, dtype=np.uint8)\n",
    "    \n",
    "    for y in range(height):\n",
    "        py = -y + height//2\n",
    "        for x in range(width):\n",
    "            px = x - width//2\n",
    "            cylinder_proj[-int(s*py/math.sqrt(px**2+f**2) - height//2)][int(s*math.atan(px/f) + width//2)] = img[y][x]\n",
    "    \n",
    "    return cylinder_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_black_edge(img, f = FOCAL_LENGTH, s = CYLINDER_RADIUS):\n",
    "    h, w = img.shape[:2]\n",
    "    top = -int(s*(h//2)/math.sqrt((-w//2)**2+f**2) - h//2)\n",
    "    down = -int(s*(-h//2)/math.sqrt((-w//2)**2+f**2) - h//2)\n",
    "    left = int(s*math.atan((-w//2)/f) + w//2)\n",
    "    right = int(s*math.atan((w//2)/f) + w//2)\n",
    "    crop_img = img[top:down, left:right] # crop 4 sides\n",
    "    # crop_img = img[:, left:right] # only crop 2 sides, left to right\n",
    "\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's better to use random sample\n",
    "def nonRANSAC(mp, th = RANSAC_THRESHHOLD): # mp = match pairs set of all images\n",
    "    best_mp = []\n",
    "\n",
    "    for i in range(len(mp)): # every pairs of different img img_x & img_x+1\n",
    "        best_vote = 0\n",
    "        best_dis = 99999\n",
    "        \n",
    "        best_mp.append(mp[i][0])\n",
    "        for j in range(len(mp[i])): # find the best pair of the two images\n",
    "            vote = 0\n",
    "            total_dis = 0\n",
    "            temp_pair = np.array(mp[i][:, :2])\n",
    "            trans_y = mp[i][j][2] - mp[i][j][0]\n",
    "            trans_x = mp[i][j][3] - mp[i][j][1]\n",
    "            # print(\"pair = ({}, {}, {}, {})\".format(mp[i][j][0], mp[i][j][1], mp[i][j][2], mp[i][j][3]))\n",
    "            # print(\"trans = {}, {}\".format(trans_y, trans_x))\n",
    "            temp_pair[:, 0] = temp_pair[:, 0] + trans_y - mp[i][:, 2]\n",
    "            temp_pair[:, 1] = temp_pair[:, 1] + trans_x - mp[i][:, 3]\n",
    "            # print(\"temp_pair.len = {}\".format(len(temp_pair)))\n",
    "            for k in range(len(temp_pair)):\n",
    "                # print(\"k_pair = {}, norm = {}\".format(temp_pair[k], la.norm(temp_pair[k])))\n",
    "                if(la.norm(temp_pair[k]) < th):\n",
    "                    vote += 1\n",
    "                    total_dis += la.norm(temp_pair[k])**2\n",
    "\n",
    "\n",
    "\n",
    "            if(vote >= best_vote):\n",
    "                if(total_dis < best_dis and total_dis > 0):\n",
    "                    best_dis = total_dis\n",
    "                    best_vote = vote\n",
    "                    best_mp[i] = mp[i][j]\n",
    "\n",
    "\n",
    "    # for z in range(len(best_mp)):\n",
    "    #     print(\"mp[0]: {}, best[0]: {}\".format(mp[z][0], best_mp[z]))\n",
    "\n",
    "    return best_mp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  img2       img1            img2+img1\n",
    "#  _____      _____           _____\n",
    "# |     |    |.    |  __\\    |    _|___   shift = (c,d) - (a,b)\n",
    "# |    .|    |     |     \\   |   |.|   |\n",
    "# |_____|    |_____|  __ /   |___|_|   |\n",
    "#  (c,d)      (a,b)     /        |_____|\n",
    "# \n",
    "# y shift > 0, means img1 move down\n",
    "# x shift > 0, means img1 move right\n",
    "# in our case, our image are counterclockwise and equal size, so x shift must > 0\n",
    "\n",
    "def stitch_image(img1, img2, shift): # img1 may be bigger, img2 is always the same size\n",
    "    img1_padding = [\n",
    "        (shift[0], 0) if shift[0] > 0 else (0, -shift[0]), \n",
    "        (shift[1], 0) if shift[1] > 0 else (0, -shift[1]), \n",
    "        (0, 0)\n",
    "    ]\n",
    "    padded_img1 = np.lib.pad(img1, img1_padding, 'constant', constant_values=0)\n",
    "\n",
    "    h_2 = padded_img1.shape[0] - img2.shape[0]\n",
    "    w_2 = padded_img1.shape[1] - img2.shape[1]\n",
    "    img2_padding = [\n",
    "        (h_2, 0) if shift[0] < 0 else (0, h_2), \n",
    "        (w_2, 0) if shift[1] < 0 else (0, w_2), \n",
    "        (0, 0)\n",
    "    ]\n",
    "    padded_img2 = np.lib.pad(img2, img2_padding, 'constant', constant_values=0)\n",
    "\n",
    "    new_img = alpha_blending(padded_img1, padded_img2, img2.shape,shift)\n",
    "\n",
    "    # padded_img1[:img2.shape[0], :img2.shape[1]] = img2\n",
    "\n",
    "    return new_img\n",
    "    # for i in range(len(match_points)): \n",
    "    #     img_concat = imgs[i+1]\n",
    "\n",
    "    #     img_w = imgs[i].shape[1]\n",
    "    #     for j in match_points[i]:\n",
    "    #         img_concat = cv2.line(img_concat, (j[1], j[0]), (j[3]+img_w, j[2]), (255,0,0), 1)\n",
    "\n",
    "    #     cv2.imwrite(f'result{i}_{i+1}.jpg', img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_blending(img1, img2, img2_shape, shift):\n",
    "    # blending area  = (shift[0], shift[1]) ___ (shift[0], img2.shape[1])\n",
    "    #                                      |   |\n",
    "    #             (img2.shape[0], shift[1])|___|(img2.shape[0], img2.shape[1])\n",
    "    #\n",
    "    #     (img1.shape[0]-img2_size_h, shift[1]) ___ (img1.shape[0]-img2_size_h, img2.shape[1])\n",
    "    #                                          |   |\n",
    "    #            (img1.shape[0]-as_h, shift[1])|___|(img1.shape[0]-as_h, img2.shape[1])\n",
    "    as_h, as_w = abs(shift[0]), abs(shift[1])\n",
    "    img2_size_h, img2_size_w = img2_shape[:2]\n",
    "    img_concat = np.zeros(shape=img1.shape, dtype=np.uint8)\n",
    "    img_concat = np.add(img_concat, img1)\n",
    "    img_concat = np.add(img_concat, img2)\n",
    "\n",
    "    w = img2_size_w - as_w\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    for i in range(w):\n",
    "        # img_concat[as_h:img2_size_h, w+i] = (0,0,0)\n",
    "        if(shift[0] < 0):\n",
    "            # y0 = img1.shape[0] - img2_size_h\n",
    "            y0 = as_h\n",
    "            y1 = img1.shape[0] - as_h\n",
    "            img_concat[y0:y1, as_w+i] = img2[y0:y1, as_w+i]*(w-i)/w + img1[y0:y1, as_w+i]*i/w\n",
    "            # img_concat[y0:y1, as_w+i] = 0\n",
    "        else:\n",
    "            img_concat[as_h:img2_size_h, as_w+i] = img2[as_h:img2_size_h, as_w+i]*(w-i)/w + img1[as_h:img2_size_h, as_w+i]*i/w \n",
    "\n",
    "    img1 = img1.astype(np.uint8)\n",
    "    img2 = img2.astype(np.uint8)\n",
    "    img_concat = img_concat.astype(np.uint8)\n",
    "\n",
    "    cv2.imwrite(\"test_blending.jpg\", img_concat)\n",
    "\n",
    "    return img_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Harris corner.\n",
      "Genetating images feature descriptor.\n",
      "Matching descriptor.\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "# images = load_images_from_folder('img/csie')\n",
    "# images = load_images_from_folder('img/gym/2-2', 10)\n",
    "images = load_images_from_folder('img/ours/1', 10)\n",
    "\n",
    "cylinder_images = [crop_image_black_edge(project_to_cylinder(i)) for i in images]\n",
    "\n",
    "# return match point \n",
    "match_points = output_matching_image(cylinder_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64)]"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_match_line(cylinder_images, match_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HanWen\\Downloads\\NTU_VFX_Image_Stitching\\img_stitching_koach_0430.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000046?line=0'>1</a>\u001b[0m ransac_mp \u001b[39m=\u001b[39m nonRANSAC(match_points[\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000046?line=1'>2</a>\u001b[0m shifts \u001b[39m=\u001b[39m [ransac_mp[i][\u001b[39m2\u001b[39m:] \u001b[39m-\u001b[39m ransac_mp[i][:\u001b[39m2\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ransac_mp))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000046?line=2'>3</a>\u001b[0m temp_img \u001b[39m=\u001b[39m cylinder_images[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\HanWen\\Downloads\\NTU_VFX_Image_Stitching\\img_stitching_koach_0430.ipynb Cell 17'\u001b[0m in \u001b[0;36mnonRANSAC\u001b[1;34m(mp, th)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000021?line=5'>6</a>\u001b[0m best_vote \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000021?line=6'>7</a>\u001b[0m best_dis \u001b[39m=\u001b[39m \u001b[39m99999\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000021?line=8'>9</a>\u001b[0m best_mp\u001b[39m.\u001b[39mappend(mp[i][\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000021?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(mp[i])): \u001b[39m# find the best pair of the two images\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HanWen/Downloads/NTU_VFX_Image_Stitching/img_stitching_koach_0430.ipynb#ch0000021?line=10'>11</a>\u001b[0m     vote \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "ransac_mp = nonRANSAC(match_points[1:])\n",
    "shifts = [ransac_mp[i][2:] - ransac_mp[i][:2] for i in range(len(ransac_mp))]\n",
    "temp_img = cylinder_images[0]\n",
    "for t in range(0, len(ransac_mp)):\n",
    "    temp_img = stitch_image(temp_img, cylinder_images[t+1], shifts[t])\n",
    "    cv2.imwrite(f\"shift_result{t}_{t+1}.jpg\", temp_img)\n",
    "# stitch_image(cylinder_images[0], cylinder_images[1], (-53, 125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613, 2059, 3)\n",
      "114 213\n"
     ]
    }
   ],
   "source": [
    "# temp_img = cylinder_images[0].copy()\n",
    "print(temp_img.shape)\n",
    "threshold_to_clip = cylinder_images[0].shape[1]\n",
    "temp_img_sum = np.sum(temp_img, axis=2)\n",
    "\n",
    "height_from_top = 0\n",
    "for i in temp_img:\n",
    "    if(len(np.where(i==0)[0])<threshold_to_clip):\n",
    "        break\n",
    "    height_from_top+=1\n",
    "\n",
    "height_from_bot = 0\n",
    "for i in temp_img[::-1]:\n",
    "    if(len(np.where(i==0)[0])<threshold_to_clip):\n",
    "        break\n",
    "    height_from_bot+=1\n",
    "\n",
    "print(height_from_top, height_from_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_temp_img = temp_img[height_from_top:temp_img.shape[0]-height_from_bot,:,:]\n",
    "cv2.imwrite('crop_temp_img.jpg',crop_temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([\n",
    "    [0,0,0],\n",
    "    [1,0,0],\n",
    "    [1,1,0],\n",
    "    [1,1,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "3\n",
      "[1 0 0]\n",
      "2\n",
      "[1 1 0]\n",
      "1\n",
      "[1 1 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)\n",
    "    \n",
    "    print(len(np.where(i==0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e30d277152b04c77de2258da9de4149228d00c6960d1c62da5d7e3583d03ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
