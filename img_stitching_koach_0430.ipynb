{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show img for testing\n",
    "def show_image_by_OpenCV(img):\n",
    "    cv2.imshow('My Image', img )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    paths = glob.glob(os.path.join(folder,'*'))\n",
    "    images = [cv2.imread(i) for i in paths]\n",
    "    images = [cv2.resize(i, (i.shape[0]//10, i.shape[1]//10), interpolation=cv2.INTER_AREA) for i in images]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonmax_suppression(image):\n",
    "\n",
    "    NONMAX_SUPPRESSION_KERNEL = 15\n",
    "    STRIDE = 15\n",
    "    \n",
    "    result = np.zeros((image.shape))\n",
    "    \n",
    "    _image = np.lib.stride_tricks.sliding_window_view(image, NONMAX_SUPPRESSION_KERNEL, 1)[:,::STRIDE]\n",
    "    _image = np.lib.stride_tricks.sliding_window_view(_image, NONMAX_SUPPRESSION_KERNEL, 0)[::STRIDE,:]\n",
    "    # print(_image.shape)\n",
    "    _image = np.reshape(_image,(*_image.shape[:2],-1))\n",
    "    _image = np.argmax(_image, axis=2)\n",
    "\n",
    "    mg = np.mgrid[0:_image.shape[0],0:_image.shape[1]]\n",
    "\n",
    "    # y offset: mg[0], x offset: mg[1]\n",
    "    index_y = _image // NONMAX_SUPPRESSION_KERNEL + mg[0] * STRIDE \n",
    "    index_x = _image % NONMAX_SUPPRESSION_KERNEL + mg[1] * STRIDE \n",
    "    index_x, index_y = index_x.flatten(), index_y.flatten()\n",
    "\n",
    "\n",
    "    for i, j in zip(index_y, index_x):\n",
    "        result[i][j]=image[i][j]  \n",
    "        \n",
    "    return  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_Harris_corner(image):\n",
    "    # parameters\n",
    "    KERNEL_SIZE = 11\n",
    "    THRESHOLD = 100\n",
    "    K = 0.04\n",
    "\n",
    "    #  Compute x and y derivatives of image.\n",
    "    # rgb to grayscale\n",
    "    Gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "    # gaussion : to do small smooth\n",
    "    Gau_img = cv2.GaussianBlur(Gray_img, (5,5),5)\n",
    "    # gradient\n",
    "    I_y = np.gradient(Gau_img, axis=0) \n",
    "    I_x = np.gradient(Gau_img, axis=1) \n",
    "\n",
    "\n",
    "    # Compute products of derivates at each pixel.\n",
    "    I_xx = I_x * I_x\n",
    "    I_yy = I_y * I_y\n",
    "    I_xy = I_x * I_y\n",
    "\n",
    "    # Compute the sums of the products of derivates at each pixel.\n",
    "    # weight : use gaussian\n",
    "    S_xx = cv2.GaussianBlur(I_xx, (KERNEL_SIZE,KERNEL_SIZE),KERNEL_SIZE)\n",
    "    S_yy = cv2.GaussianBlur(I_yy, (KERNEL_SIZE,KERNEL_SIZE),KERNEL_SIZE)\n",
    "    S_xy = cv2.GaussianBlur(I_xy, (KERNEL_SIZE,KERNEL_SIZE),KERNEL_SIZE)\n",
    "    \n",
    "    # Define the matrix M.\n",
    "    # | S_xx  S_xy |\n",
    "    # | S_xy  S_yy |\n",
    "\n",
    "    # Compute the response of the detector at each pixel\n",
    "    detM = S_xx * S_yy - S_xy * S_xy\n",
    "    traceM = S_xx + S_yy\n",
    "    R = detM - K * (traceM * traceM)\n",
    "\n",
    "    # Nonmax Suppression\n",
    "    R = nonmax_suppression(R)\n",
    "    \n",
    "    # Threshold on value of R\n",
    "    R[R < THRESHOLD] = 0\n",
    "    R[R > 0] = 255\n",
    "\n",
    "    \n",
    "    # 濾邊界\n",
    "    R[:20 , :] = 0\n",
    "    R[: ,:20 ] = 0\n",
    "    R[-20:, :] = 0\n",
    "    R[:,-20: ] = 0\n",
    "    # return mask\n",
    "    # print(R.shape)\n",
    "    return R\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_descriptor(feature_mask, image):\n",
    "\n",
    "    Gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "    gau_img = cv2.GaussianBlur(Gray_img, (3,3), 3)\n",
    "    sobel_y = cv2.Sobel(gau_img, cv2.CV_64F, 0, 1)\n",
    "    sobel_x = cv2.Sobel(gau_img, cv2.CV_64F, 1, 0)\n",
    "    _, angle = cv2.cartToPolar(sobel_x, sobel_y, angleInDegrees=True)\n",
    "    # print(angle.dtype)\n",
    "    DESCRIPTOR_SIZE = 40\n",
    "    KERNEL = 5\n",
    "\n",
    "    # descriptor size: 40*40\n",
    "    feature_point_y, feature_point_x = np.nonzero(feature_mask)\n",
    "    index_to_get = [KERNEL//2 + i * KERNEL for i in range(DESCRIPTOR_SIZE//KERNEL)]\n",
    "    # 5*5 sum/mean -> 8*8(descriptor matrix)\n",
    "\n",
    "    descriptors = []\n",
    "    positions = []\n",
    "    for y, x in zip(feature_point_y, feature_point_x):\n",
    "        y, x = int(y), int(x)\n",
    "        rot_M = cv2.getRotationMatrix2D((x,y),angle[y,x],1) # (旋轉中心),旋轉角度,縮放比例\n",
    "        img_rotate = cv2.warpAffine(gau_img,rot_M,(gau_img.shape[1],gau_img.shape[0]), flags = cv2.INTER_NEAREST)\n",
    "\n",
    "        # 取feature_point-20~+19之間的值，做boxfilter\n",
    "        big_matrix = img_rotate[y-DESCRIPTOR_SIZE//2:y+DESCRIPTOR_SIZE//2, x-DESCRIPTOR_SIZE//2:x+DESCRIPTOR_SIZE//2]\n",
    "        big_matrix = cv2.boxFilter(big_matrix, -1, (KERNEL, KERNEL))\n",
    "        # print(big_matrix.dtype)\n",
    "        # size = (8, 8)\n",
    "        descriptor = np.zeros((DESCRIPTOR_SIZE//KERNEL, DESCRIPTOR_SIZE//KERNEL))\n",
    "        for i in range(DESCRIPTOR_SIZE//KERNEL):\n",
    "            for j in range(DESCRIPTOR_SIZE//KERNEL):\n",
    "                descriptor[i][j] = big_matrix[index_to_get[i]][index_to_get[j]]\n",
    "        descriptor = (descriptor - np.mean(descriptor)) / np.std(descriptor)\n",
    "        descriptors.append(descriptor)\n",
    "        positions.append([y, x])\n",
    "\n",
    "    return np.array(descriptors), np.array(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match_poing(descriptors_1, positions_1, descriptors_2, positions_2, LOW_THERESHOLD=2.0):\n",
    "    match_point = []\n",
    "    # match_dis = []\n",
    "    \n",
    "    for ds1, ps1 in zip(descriptors_1, positions_1):\n",
    "        min_dis = 99999\n",
    "        min_pos = [-1, -1]\n",
    "\n",
    "        for ds2, ps2 in zip(descriptors_2, positions_2):\n",
    "            dis = np.linalg.norm(ds1 - ds2)\n",
    "\n",
    "            if(dis<min_dis):\n",
    "                min_dis = dis\n",
    "                min_pos = np.array([*ps1, *ps2])\n",
    "                \n",
    "        if(min_dis<LOW_THERESHOLD):\n",
    "            match_point.append(min_pos)\n",
    "            # match_dis.append(min_dis)\n",
    "    return match_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(descriptors_1, positions_1, descriptors_2, positions_2):\n",
    "    # print('find_match_poing1')\n",
    "    match_point_to_1 = find_match_poing(descriptors_1, positions_1, descriptors_2, positions_2)\n",
    "    \n",
    "    # print('find_match_poing2')\n",
    "    match_point_to_2 = find_match_poing(descriptors_2, positions_2, descriptors_1, positions_1)\n",
    "\n",
    "    # print('merge')\n",
    "    match_point = []\n",
    "    for match_1 in match_point_to_1:\n",
    "        for match_2 in match_point_to_2:\n",
    "            dis_1 = np.linalg.norm(match_1[:2]-match_2[-2:])\n",
    "            dis_2 = np.linalg.norm(match_1[-2:]-match_2[:2])\n",
    "            \n",
    "            if(dis_1+dis_2==0):\n",
    "                match_point.append(match_1)\n",
    "                \n",
    "    return np.array(match_point)\n",
    "    \n",
    "    # [pos1_y, pos1_x, pos2_y, pos2_x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point(img, R, output, outputName, r, g, b):\n",
    "    for i in range(R.shape[0]):\n",
    "        for j in range(R.shape[1]):\n",
    "            if (R[i][j]>1):\n",
    "                img = cv2.circle(img, (j, i), 2, (b, g, r), 2)\n",
    "    if(output):\n",
    "        cv2.imwrite(f\"{outputName}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_matching_image(images):\n",
    "    print('Detecting Harris corner.')\n",
    "    imgs_detect_Harris_corner = [detect_Harris_corner(i) for i in images]\n",
    "    \n",
    "    print('Genetating images feature descriptor.')\n",
    "    for i, j in zip(images, imgs_detect_Harris_corner):\n",
    "        draw_point(i, j, 0, '', 255, 0, 0) \n",
    "    dsps = [feature_descriptor(i, j)for i,j in zip(imgs_detect_Harris_corner, images)]\n",
    "    match_points = []\n",
    "\n",
    "    print('Matching descriptor.')\n",
    "    for i in range(1, len(images)):\n",
    "        match_points.append(matching(dsps[i-1][0], dsps[i-1][1], dsps[i][0], dsps[i][1]))\n",
    "    return match_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_match_line(imgs, match_points):\n",
    "    for i in range(len(match_points)): \n",
    "        img_concat = np.concatenate((imgs[i], imgs[i+1]), axis=1)\n",
    "        img_w = imgs[i].shape[1]\n",
    "        for j in match_points[i]:\n",
    "            img_concat = cv2.line(img_concat, (j[1], j[0]), (j[3]+img_w, j[2]), (255,0,0), 1)\n",
    "\n",
    "        cv2.imwrite(f'result{i}_{i+1}.jpg', img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Harris corner.\n",
      "Genetating images feature descriptor.\n",
      "Matching descriptor.\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "images = load_images_from_folder('img/gym/2-2')\n",
    "\n",
    "# return match point \n",
    "match_points = output_matching_image(images)\n",
    "\n",
    "draw_match_line(images, match_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na = load_images_from_folder(\\'img/test\\')\\nR = detect_Harris_corner(a[0])\\nR2 = detect_Harris_corner(a[1])\\n\\nfor i in range(R.shape[0]):\\n    for j in range(R.shape[1]):\\n        if (R[i][j]>1):\\n            a[0] = cv2.circle(a[0], (j, i), 2, (0, 0, 255), 2)\\n\\ncv2.imwrite(\"R1.jpg\", a[0])\\n\\nfor i in range(R2.shape[0]):\\n    for j in range(R2.shape[1]):\\n        if (R2[i][j]>1):\\n            a[1] = cv2.circle(a[1], (j, i), 2, (0, 0, 255), 2)\\n\\ncv2.imwrite(\"R2.jpg\", a[1])\\nds1, ps1 = feature_descriptor(R, a[0])\\nds2, ps2 = feature_descriptor(R2, a[1])\\nmpm = matching(ds1, ps1, ds2, ps2)\\nimg_concat = np.concatenate((a[0], a[1]), axis=1)\\n\\nimg_w = a[0].shape[1]\\n\\nfor i in range(len(mpm)):\\n    img_concat = cv2.line(img_concat, (mpm[i][1], mpm[i][0]), (mpm[i][3]+img_w, mpm[i][2]), (255,0,0), 1)\\n\\ncv2.imwrite(\"result04.jpg\", img_concat)\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a = load_images_from_folder('img/test')\n",
    "R = detect_Harris_corner(a[0])\n",
    "R2 = detect_Harris_corner(a[1])\n",
    "\n",
    "for i in range(R.shape[0]):\n",
    "    for j in range(R.shape[1]):\n",
    "        if (R[i][j]>1):\n",
    "            a[0] = cv2.circle(a[0], (j, i), 2, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imwrite(\"R1.jpg\", a[0])\n",
    "\n",
    "for i in range(R2.shape[0]):\n",
    "    for j in range(R2.shape[1]):\n",
    "        if (R2[i][j]>1):\n",
    "            a[1] = cv2.circle(a[1], (j, i), 2, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imwrite(\"R2.jpg\", a[1])\n",
    "ds1, ps1 = feature_descriptor(R, a[0])\n",
    "ds2, ps2 = feature_descriptor(R2, a[1])\n",
    "mpm = matching(ds1, ps1, ds2, ps2)\n",
    "img_concat = np.concatenate((a[0], a[1]), axis=1)\n",
    "\n",
    "img_w = a[0].shape[1]\n",
    "\n",
    "for i in range(len(mpm)):\n",
    "    img_concat = cv2.line(img_concat, (mpm[i][1], mpm[i][0]), (mpm[i][3]+img_w, mpm[i][2]), (255,0,0), 1)\n",
    "\n",
    "cv2.imwrite(\"result04.jpg\", img_concat)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e30d277152b04c77de2258da9de4149228d00c6960d1c62da5d7e3583d03ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
